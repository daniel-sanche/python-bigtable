# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# This file is automatically generated by sync_surface_generator.py. Do not edit.


from abc import ABC
from unittest import mock
import concurrent.futures
import mock
import pytest
import time

from google.cloud.bigtable.data import TABLE_DEFAULT
from google.cloud.bigtable.data.exceptions import _MutateRowsIncomplete
import google.api_core.exceptions as core_exceptions


class TestMutationsBatcher(ABC):
    def _get_target_class(self):
        from google.cloud.bigtable.data._sync.mutations_batcher import MutationsBatcher

        return MutationsBatcher

    def _get_mutate_rows_class_path(self):
        return "google.cloud.bigtable.data._sync._mutate_rows._MutateRowsOperation"

    def _make_one(self, table=None, **kwargs):
        from google.api_core.exceptions import DeadlineExceeded
        from google.api_core.exceptions import ServiceUnavailable

        if table is None:
            table = mock.Mock()
            table.default_mutate_rows_operation_timeout = 10
            table.default_mutate_rows_attempt_timeout = 10
            table.default_mutate_rows_retryable_errors = (
                DeadlineExceeded,
                ServiceUnavailable,
            )
        return self._get_target_class()(table, **kwargs)

    @staticmethod
    def _make_mutation(count=1, size=1):
        mutation = mock.Mock()
        mutation.size.return_value = size
        mutation.mutations = [mock.Mock()] * count
        return mutation

    def test_ctor_defaults(self):
        with mock.patch.object(
            self._get_target_class(),
            "_start_flush_timer",
            return_value=concurrent.futures.Future(),
        ) as flush_timer_mock:
            table = mock.Mock()
            table.default_mutate_rows_operation_timeout = 10
            table.default_mutate_rows_attempt_timeout = 8
            table.default_mutate_rows_retryable_errors = [Exception]
            with self._make_one(table) as instance:
                assert instance._table == table
                assert instance.closed is False
                assert instance._flush_jobs == set()
                assert len(instance._staged_entries) == 0
                assert len(instance._oldest_exceptions) == 0
                assert len(instance._newest_exceptions) == 0
                assert instance._exception_list_limit == 10
                assert instance._exceptions_since_last_raise == 0
                assert instance._flow_control._max_mutation_count == 100000
                assert instance._flow_control._max_mutation_bytes == 104857600
                assert instance._flow_control._in_flight_mutation_count == 0
                assert instance._flow_control._in_flight_mutation_bytes == 0
                assert instance._entries_processed_since_last_raise == 0
                assert (
                    instance._operation_timeout
                    == table.default_mutate_rows_operation_timeout
                )
                assert (
                    instance._attempt_timeout
                    == table.default_mutate_rows_attempt_timeout
                )
                assert (
                    instance._retryable_errors
                    == table.default_mutate_rows_retryable_errors
                )
                time.sleep(0)
                assert flush_timer_mock.call_count == 1
                assert flush_timer_mock.call_args[0][0] == 5
                assert isinstance(instance._flush_timer, concurrent.futures.Future)

    def test_ctor_explicit(self):
        """Test with explicit parameters"""
        with mock.patch.object(
            self._get_target_class(),
            "_start_flush_timer",
            return_value=concurrent.futures.Future(),
        ) as flush_timer_mock:
            table = mock.Mock()
            flush_interval = 20
            flush_limit_count = 17
            flush_limit_bytes = 19
            flow_control_max_mutation_count = 1001
            flow_control_max_bytes = 12
            operation_timeout = 11
            attempt_timeout = 2
            retryable_errors = [Exception]
            with self._make_one(
                table,
                flush_interval=flush_interval,
                flush_limit_mutation_count=flush_limit_count,
                flush_limit_bytes=flush_limit_bytes,
                flow_control_max_mutation_count=flow_control_max_mutation_count,
                flow_control_max_bytes=flow_control_max_bytes,
                batch_operation_timeout=operation_timeout,
                batch_attempt_timeout=attempt_timeout,
                batch_retryable_errors=retryable_errors,
            ) as instance:
                assert instance._table == table
                assert instance.closed is False
                assert instance._flush_jobs == set()
                assert len(instance._staged_entries) == 0
                assert len(instance._oldest_exceptions) == 0
                assert len(instance._newest_exceptions) == 0
                assert instance._exception_list_limit == 10
                assert instance._exceptions_since_last_raise == 0
                assert (
                    instance._flow_control._max_mutation_count
                    == flow_control_max_mutation_count
                )
                assert (
                    instance._flow_control._max_mutation_bytes == flow_control_max_bytes
                )
                assert instance._flow_control._in_flight_mutation_count == 0
                assert instance._flow_control._in_flight_mutation_bytes == 0
                assert instance._entries_processed_since_last_raise == 0
                assert instance._operation_timeout == operation_timeout
                assert instance._attempt_timeout == attempt_timeout
                assert instance._retryable_errors == retryable_errors
                time.sleep(0)
                assert flush_timer_mock.call_count == 1
                assert flush_timer_mock.call_args[0][0] == flush_interval
                assert isinstance(instance._flush_timer, concurrent.futures.Future)

    def test_ctor_no_flush_limits(self):
        """Test with None for flush limits"""
        with mock.patch.object(
            self._get_target_class(),
            "_start_flush_timer",
            return_value=concurrent.futures.Future(),
        ) as flush_timer_mock:
            table = mock.Mock()
            table.default_mutate_rows_operation_timeout = 10
            table.default_mutate_rows_attempt_timeout = 8
            table.default_mutate_rows_retryable_errors = ()
            flush_interval = None
            flush_limit_count = None
            flush_limit_bytes = None
            with self._make_one(
                table,
                flush_interval=flush_interval,
                flush_limit_mutation_count=flush_limit_count,
                flush_limit_bytes=flush_limit_bytes,
            ) as instance:
                assert instance._table == table
                assert instance.closed is False
                assert instance._staged_entries == []
                assert len(instance._oldest_exceptions) == 0
                assert len(instance._newest_exceptions) == 0
                assert instance._exception_list_limit == 10
                assert instance._exceptions_since_last_raise == 0
                assert instance._flow_control._in_flight_mutation_count == 0
                assert instance._flow_control._in_flight_mutation_bytes == 0
                assert instance._entries_processed_since_last_raise == 0
                time.sleep(0)
                assert flush_timer_mock.call_count == 1
                assert flush_timer_mock.call_args[0][0] is None
                assert isinstance(instance._flush_timer, concurrent.futures.Future)

    def test_ctor_invalid_values(self):
        """Test that timeout values are positive, and fit within expected limits"""
        with pytest.raises(ValueError) as e:
            self._make_one(batch_operation_timeout=-1)
        assert "operation_timeout must be greater than 0" in str(e.value)
        with pytest.raises(ValueError) as e:
            self._make_one(batch_attempt_timeout=-1)
        assert "attempt_timeout must be greater than 0" in str(e.value)

    def test_default_argument_consistency(self):
        """
        We supply default arguments in MutationsBatcherAsync.__init__, and in
        table.mutations_batcher. Make sure any changes to defaults are applied to
        both places
        """
        from google.cloud.bigtable.data._async.client import TableAsync
        from google.cloud.bigtable.data._async.mutations_batcher import (
            MutationsBatcherAsync,
        )
        import inspect

        get_batcher_signature = dict(
            inspect.signature(TableAsync.mutations_batcher).parameters
        )
        get_batcher_signature.pop("self")
        batcher_init_signature = dict(
            inspect.signature(MutationsBatcherAsync).parameters
        )
        batcher_init_signature.pop("table")
        assert len(get_batcher_signature.keys()) == len(batcher_init_signature.keys())
        assert len(get_batcher_signature) == 8
        assert set(get_batcher_signature.keys()) == set(batcher_init_signature.keys())
        for arg_name in get_batcher_signature.keys():
            assert (
                get_batcher_signature[arg_name].default
                == batcher_init_signature[arg_name].default
            )

    def test__start_flush_timer_w_None(self):
        """Empty timer should return immediately"""
        with mock.patch.object(
            self._get_target_class(), "_schedule_flush"
        ) as flush_mock:
            with self._make_one() as instance:
                with mock.patch("asyncio.sleep") as sleep_mock:
                    instance._start_flush_timer(None)
                    assert sleep_mock.call_count == 0
                    assert flush_mock.call_count == 0

    def test__start_flush_timer_call_when_closed(self):
        """closed batcher's timer should return immediately"""
        with mock.patch.object(
            self._get_target_class(), "_schedule_flush"
        ) as flush_mock:
            with self._make_one() as instance:
                instance.close()
                flush_mock.reset_mock()
                with mock.patch("asyncio.sleep") as sleep_mock:
                    instance._start_flush_timer(1)
                    assert sleep_mock.call_count == 0
                    assert flush_mock.call_count == 0

    def test__flush_timer(self):
        """Timer should continue to call _schedule_flush in a loop"""
        with mock.patch.object(
            self._get_target_class(), "_schedule_flush"
        ) as flush_mock:
            expected_sleep = 12
            with self._make_one(flush_interval=expected_sleep) as instance:
                instance._staged_entries = [mock.Mock()]
                loop_num = 3
                with mock.patch("asyncio.sleep") as sleep_mock:
                    sleep_mock.side_effect = [None] * loop_num + [
                        ZeroDivisionError("expected")
                    ]
                    try:
                        instance._flush_timer
                    except ZeroDivisionError:
                        instance._flush_timer = concurrent.futures.Future()
                    assert sleep_mock.call_count == loop_num + 1
                    sleep_mock.assert_called_with(expected_sleep)
                    assert flush_mock.call_count == loop_num

    def test__flush_timer_no_mutations(self):
        """Timer should not flush if no new mutations have been staged"""
        with mock.patch.object(
            self._get_target_class(), "_schedule_flush"
        ) as flush_mock:
            expected_sleep = 12
            with self._make_one(flush_interval=expected_sleep) as instance:
                loop_num = 3
                with mock.patch("asyncio.sleep") as sleep_mock:
                    sleep_mock.side_effect = [None] * loop_num + [TabError("expected")]
                    try:
                        instance._flush_timer
                    except TabError:
                        instance._flush_timer = concurrent.futures.Future()
                    assert sleep_mock.call_count == loop_num + 1
                    sleep_mock.assert_called_with(expected_sleep)
                    assert flush_mock.call_count == 0

    def test__flush_timer_close(self):
        """Timer should continue terminate after close"""
        with mock.patch.object(
            self._get_target_class(), "_schedule_flush"
        ) as flush_mock:
            with self._make_one() as instance:
                with mock.patch("asyncio.sleep"):
                    time.sleep(0.5)
                    assert instance._flush_timer.done() is False
                    instance.close()
                    time.sleep(0.1)
                    assert instance._flush_timer.done() is True

    def test_append_closed(self):
        """Should raise exception"""
        with pytest.raises(RuntimeError):
            instance = self._make_one()
            instance.close()
            instance.append(mock.Mock())

    def test_append_wrong_mutation(self):
        """
        Mutation objects should raise an exception.
        Only support RowMutationEntry
        """
        from google.cloud.bigtable.data.mutations import DeleteAllFromRow

        with self._make_one() as instance:
            expected_error = "invalid mutation type: DeleteAllFromRow. Only RowMutationEntry objects are supported by batcher"
            with pytest.raises(ValueError) as e:
                instance.append(DeleteAllFromRow())
            assert str(e.value) == expected_error

    def test_append_outside_flow_limits(self):
        """entries larger than mutation limits are still processed"""
        with self._make_one(
            flow_control_max_mutation_count=1, flow_control_max_bytes=1
        ) as instance:
            oversized_entry = self._make_mutation(count=0, size=2)
            instance.append(oversized_entry)
            assert instance._staged_entries == [oversized_entry]
            assert instance._staged_count == 0
            assert instance._staged_bytes == 2
            instance._staged_entries = []
        with self._make_one(
            flow_control_max_mutation_count=1, flow_control_max_bytes=1
        ) as instance:
            overcount_entry = self._make_mutation(count=2, size=0)
            instance.append(overcount_entry)
            assert instance._staged_entries == [overcount_entry]
            assert instance._staged_count == 2
            assert instance._staged_bytes == 0
            instance._staged_entries = []

    def test_append_flush_runs_after_limit_hit(self):
        """
        If the user appends a bunch of entries above the flush limits back-to-back,
        it should still flush in a single task
        """
        with mock.patch.object(
            self._get_target_class(), "_execute_mutate_rows"
        ) as op_mock:
            with self._make_one(flush_limit_bytes=100) as instance:

                def mock_call(*args, **kwargs):
                    return []

                op_mock.side_effect = mock_call
                instance.append(self._make_mutation(size=99))
                num_entries = 10
                for _ in range(num_entries):
                    instance.append(self._make_mutation(size=1))
                print(*instance._flush_jobs)
                assert op_mock.call_count == 1
                sent_batch = op_mock.call_args[0][0]
                assert len(sent_batch) == 2
                assert len(instance._staged_entries) == num_entries - 1

    @pytest.mark.parametrize(
        "flush_count,flush_bytes,mutation_count,mutation_bytes,expect_flush",
        [
            (10, 10, 1, 1, False),
            (10, 10, 9, 9, False),
            (10, 10, 10, 1, True),
            (10, 10, 1, 10, True),
            (10, 10, 10, 10, True),
            (1, 1, 10, 10, True),
            (1, 1, 0, 0, False),
        ],
    )
    def test_append(
        self, flush_count, flush_bytes, mutation_count, mutation_bytes, expect_flush
    ):
        """test appending different mutations, and checking if it causes a flush"""
        with self._make_one(
            flush_limit_mutation_count=flush_count, flush_limit_bytes=flush_bytes
        ) as instance:
            assert instance._staged_count == 0
            assert instance._staged_bytes == 0
            assert instance._staged_entries == []
            mutation = self._make_mutation(count=mutation_count, size=mutation_bytes)
            with mock.patch.object(instance, "_schedule_flush") as flush_mock:
                instance.append(mutation)
            assert flush_mock.call_count == bool(expect_flush)
            assert instance._staged_count == mutation_count
            assert instance._staged_bytes == mutation_bytes
            assert instance._staged_entries == [mutation]
            instance._staged_entries = []

    def test_append_multiple_sequentially(self):
        """Append multiple mutations"""
        with self._make_one(
            flush_limit_mutation_count=8, flush_limit_bytes=8
        ) as instance:
            assert instance._staged_count == 0
            assert instance._staged_bytes == 0
            assert instance._staged_entries == []
            mutation = self._make_mutation(count=2, size=3)
            with mock.patch.object(instance, "_schedule_flush") as flush_mock:
                instance.append(mutation)
                assert flush_mock.call_count == 0
                assert instance._staged_count == 2
                assert instance._staged_bytes == 3
                assert len(instance._staged_entries) == 1
                instance.append(mutation)
                assert flush_mock.call_count == 0
                assert instance._staged_count == 4
                assert instance._staged_bytes == 6
                assert len(instance._staged_entries) == 2
                instance.append(mutation)
                assert flush_mock.call_count == 1
                assert instance._staged_count == 6
                assert instance._staged_bytes == 9
                assert len(instance._staged_entries) == 3
            instance._staged_entries = []

    def test_flush_flow_control_concurrent_requests(self):
        """requests should happen in parallel if flow control breaks up single flush into batches"""
        import time

        num_calls = 10
        fake_mutations = [self._make_mutation(count=1) for _ in range(num_calls)]
        with self._make_one(flow_control_max_mutation_count=1) as instance:
            with mock.patch.object(
                instance, "_execute_mutate_rows", mock.Mock()
            ) as op_mock:

                def mock_call(*args, **kwargs):
                    time.sleep(0.1)
                    return []

                op_mock.side_effect = mock_call
                start_time = time.monotonic()
                instance._staged_entries = fake_mutations
                instance._schedule_flush()
                time.sleep(0.01)
                for i in range(num_calls):
                    instance._flow_control.remove_from_flow(
                        [self._make_mutation(count=1)]
                    )
                    time.sleep(0.01)
                print(*instance._flush_jobs)
                duration = time.monotonic() - start_time
                assert len(instance._oldest_exceptions) == 0
                assert len(instance._newest_exceptions) == 0
                assert duration < 0.5
                assert op_mock.call_count == num_calls

    def test_schedule_flush_no_mutations(self):
        """schedule flush should return None if no staged mutations"""
        with self._make_one() as instance:
            with mock.patch.object(instance, "_flush_internal") as flush_mock:
                for i in range(3):
                    assert instance._schedule_flush() is None
                    assert flush_mock.call_count == 0

    def test_schedule_flush_with_mutations(self):
        """if new mutations exist, should add a new flush task to _flush_jobs"""
        with self._make_one() as instance:
            with mock.patch.object(instance, "_flush_internal") as flush_mock:
                for i in range(1, 4):
                    mutation = mock.Mock()
                    instance._staged_entries = [mutation]
                    instance._schedule_flush()
                    assert instance._staged_entries == []
                    time.sleep(0)
                    assert instance._staged_entries == []
                    assert instance._staged_count == 0
                    assert instance._staged_bytes == 0
                    assert flush_mock.call_count == i

    def test__flush_internal(self):
        """
        _flush_internal should:
          - await previous flush call
          - delegate batching to _flow_control
          - call _execute_mutate_rows on each batch
          - update self.exceptions and self._entries_processed_since_last_raise
        """
        num_entries = 10
        with self._make_one() as instance:
            with mock.patch.object(instance, "_execute_mutate_rows") as execute_mock:
                with mock.patch.object(
                    instance._flow_control, "add_to_flow"
                ) as flow_mock:

                    def gen(x):
                        yield x

                    flow_mock.side_effect = lambda x: gen(x)
                    mutations = [self._make_mutation(count=1, size=1)] * num_entries
                    instance._flush_internal(mutations)
                    assert instance._entries_processed_since_last_raise == num_entries
                    assert execute_mock.call_count == 1
                    assert flow_mock.call_count == 1
                    instance._oldest_exceptions.clear()
                    instance._newest_exceptions.clear()

    def test_flush_clears_job_list(self):
        """
        a job should be added to _flush_jobs when _schedule_flush is called,
        and removed when it completes
        """
        with self._make_one() as instance:
            with mock.patch.object(instance, "_flush_internal", mock.Mock()):
                mutations = [self._make_mutation(count=1, size=1)]
                instance._staged_entries = mutations
                assert instance._flush_jobs == set()
                new_job = instance._schedule_flush()
                assert instance._flush_jobs == {new_job}
                new_job
                assert instance._flush_jobs == set()

    @pytest.mark.parametrize(
        "num_starting,num_new_errors,expected_total_errors",
        [
            (0, 0, 0),
            (0, 1, 1),
            (0, 2, 2),
            (1, 0, 1),
            (1, 1, 2),
            (10, 2, 12),
            (10, 20, 20),
        ],
    )
    def test__flush_internal_with_errors(
        self, num_starting, num_new_errors, expected_total_errors
    ):
        """errors returned from _execute_mutate_rows should be added to internal exceptions"""
        from google.cloud.bigtable.data import exceptions

        num_entries = 10
        expected_errors = [
            exceptions.FailedMutationEntryError(mock.Mock(), mock.Mock(), ValueError())
        ] * num_new_errors
        with self._make_one() as instance:
            instance._oldest_exceptions = [mock.Mock()] * num_starting
            with mock.patch.object(instance, "_execute_mutate_rows") as execute_mock:
                execute_mock.return_value = expected_errors
                with mock.patch.object(
                    instance._flow_control, "add_to_flow"
                ) as flow_mock:

                    def gen(x):
                        yield x

                    flow_mock.side_effect = lambda x: gen(x)
                    mutations = [self._make_mutation(count=1, size=1)] * num_entries
                    instance._flush_internal(mutations)
                    assert instance._entries_processed_since_last_raise == num_entries
                    assert execute_mock.call_count == 1
                    assert flow_mock.call_count == 1
                    found_exceptions = instance._oldest_exceptions + list(
                        instance._newest_exceptions
                    )
                    assert len(found_exceptions) == expected_total_errors
                    for i in range(num_starting, expected_total_errors):
                        assert found_exceptions[i] == expected_errors[i - num_starting]
                        assert found_exceptions[i].index is None
            instance._oldest_exceptions.clear()
            instance._newest_exceptions.clear()

    def _mock_gapic_return(self, num=5):
        from google.cloud.bigtable_v2.types import MutateRowsResponse
        from google.rpc import status_pb2

        def gen(num):
            for i in range(num):
                entry = MutateRowsResponse.Entry(
                    index=i, status=status_pb2.Status(code=0)
                )
                yield MutateRowsResponse(entries=[entry])

        return gen(num)

    def test_timer_flush_end_to_end(self):
        """Flush should automatically trigger after flush_interval"""
        num_nutations = 10
        mutations = [self._make_mutation(count=2, size=2)] * num_nutations
        with self._make_one(flush_interval=0.05) as instance:
            instance._table.default_operation_timeout = 10
            instance._table.default_attempt_timeout = 9
            with mock.patch.object(
                instance._table.client._gapic_client, "mutate_rows"
            ) as gapic_mock:
                gapic_mock.side_effect = (
                    lambda *args, **kwargs: self._mock_gapic_return(num_nutations)
                )
                for m in mutations:
                    instance.append(m)
                assert instance._entries_processed_since_last_raise == 0
                time.sleep(0.1)
                assert instance._entries_processed_since_last_raise == num_nutations

    def test__execute_mutate_rows(self):
        mutate_path = self._get_mutate_rows_class_path()
        with mock.patch(mutate_path) as mutate_rows:
            mutate_rows.return_value = mock.Mock()
            start_operation = mutate_rows().start
            table = mock.Mock()
            table.table_name = "test-table"
            table.app_profile_id = "test-app-profile"
            table.default_mutate_rows_operation_timeout = 17
            table.default_mutate_rows_attempt_timeout = 13
            table.default_mutate_rows_retryable_errors = ()
            with self._make_one(table) as instance:
                batch = [self._make_mutation()]
                result = instance._execute_mutate_rows(batch)
                assert start_operation.call_count == 1
                (args, kwargs) = mutate_rows.call_args
                assert args[0] == table.client._gapic_client
                assert args[1] == table
                assert args[2] == batch
                kwargs["operation_timeout"] == 17
                kwargs["attempt_timeout"] == 13
                assert result == []

    def test__execute_mutate_rows_returns_errors(self):
        """Errors from operation should be retruned as list"""
        from google.cloud.bigtable.data.exceptions import (
            MutationsExceptionGroup,
            FailedMutationEntryError,
        )

        cls_path = self._get_mutate_rows_class_path()
        with mock.patch(f"{cls_path}.start") as mutate_rows:
            err1 = FailedMutationEntryError(0, mock.Mock(), RuntimeError("test error"))
            err2 = FailedMutationEntryError(1, mock.Mock(), RuntimeError("test error"))
            mutate_rows.side_effect = MutationsExceptionGroup([err1, err2], 10)
            table = mock.Mock()
            table.default_mutate_rows_operation_timeout = 17
            table.default_mutate_rows_attempt_timeout = 13
            table.default_mutate_rows_retryable_errors = ()
            with self._make_one(table) as instance:
                batch = [self._make_mutation()]
                result = instance._execute_mutate_rows(batch)
                assert len(result) == 2
                assert result[0] == err1
                assert result[1] == err2
                assert result[0].index is None
                assert result[1].index is None

    def test__raise_exceptions(self):
        """Raise exceptions and reset error state"""
        from google.cloud.bigtable.data import exceptions

        expected_total = 1201
        expected_exceptions = [RuntimeError("mock")] * 3
        with self._make_one() as instance:
            instance._oldest_exceptions = expected_exceptions
            instance._entries_processed_since_last_raise = expected_total
            try:
                instance._raise_exceptions()
            except exceptions.MutationsExceptionGroup as exc:
                assert list(exc.exceptions) == expected_exceptions
                assert str(expected_total) in str(exc)
            assert instance._entries_processed_since_last_raise == 0
            (instance._oldest_exceptions, instance._newest_exceptions) = ([], [])
            instance._raise_exceptions()

    def test___aenter__(self):
        """Should return self"""
        with self._make_one() as instance:
            assert instance.__enter__() == instance

    def test___aexit__(self):
        """aexit should call close"""
        with self._make_one() as instance:
            with mock.patch.object(instance, "close") as close_mock:
                instance.__exit__(None, None, None)
                assert close_mock.call_count == 1

    def test_close(self):
        """Should clean up all resources"""
        with self._make_one() as instance:
            with mock.patch.object(instance, "_schedule_flush") as flush_mock:
                with mock.patch.object(instance, "_raise_exceptions") as raise_mock:
                    instance.close()
                    assert instance.closed is True
                    assert instance._flush_timer.done() is True
                    assert instance._flush_jobs == set()
                    assert flush_mock.call_count == 1
                    assert raise_mock.call_count == 1

    def test_close_w_exceptions(self):
        """Raise exceptions on close"""
        from google.cloud.bigtable.data import exceptions

        expected_total = 10
        expected_exceptions = [RuntimeError("mock")]
        with self._make_one() as instance:
            instance._oldest_exceptions = expected_exceptions
            instance._entries_processed_since_last_raise = expected_total
            try:
                instance.close()
            except exceptions.MutationsExceptionGroup as exc:
                assert list(exc.exceptions) == expected_exceptions
                assert str(expected_total) in str(exc)
            assert instance._entries_processed_since_last_raise == 0
            (instance._oldest_exceptions, instance._newest_exceptions) = ([], [])

    def test__on_exit(self, recwarn):
        """Should raise warnings if unflushed mutations exist"""
        with self._make_one() as instance:
            instance._on_exit()
            assert len(recwarn) == 0
            num_left = 4
            instance._staged_entries = [mock.Mock()] * num_left
            with pytest.warns(UserWarning) as w:
                instance._on_exit()
                assert len(w) == 1
                assert "unflushed mutations" in str(w[0].message).lower()
                assert str(num_left) in str(w[0].message)
            instance.closed = True
            instance._on_exit()
            assert len(recwarn) == 0
            instance._staged_entries = []

    def test_atexit_registration(self):
        """Should run _on_exit on program termination"""
        import atexit

        with mock.patch.object(atexit, "register") as register_mock:
            assert register_mock.call_count == 0
            with self._make_one():
                assert register_mock.call_count == 1

    def test_timeout_args_passed(self):
        """
        batch_operation_timeout and batch_attempt_timeout should be used
        in api calls
        """
        mutate_path = self._get_mutate_rows_class_path()
        with mock.patch(mutate_path, return_value=mock.Mock()) as mutate_rows:
            expected_operation_timeout = 17
            expected_attempt_timeout = 13
            with self._make_one(
                batch_operation_timeout=expected_operation_timeout,
                batch_attempt_timeout=expected_attempt_timeout,
            ) as instance:
                assert instance._operation_timeout == expected_operation_timeout
                assert instance._attempt_timeout == expected_attempt_timeout
                instance._execute_mutate_rows([self._make_mutation()])
                assert mutate_rows.call_count == 1
                kwargs = mutate_rows.call_args[1]
                assert kwargs["operation_timeout"] == expected_operation_timeout
                assert kwargs["attempt_timeout"] == expected_attempt_timeout

    @pytest.mark.parametrize(
        "limit,in_e,start_e,end_e",
        [
            (10, 0, (10, 0), (10, 0)),
            (1, 10, (0, 0), (1, 1)),
            (10, 1, (0, 0), (1, 0)),
            (10, 10, (0, 0), (10, 0)),
            (10, 11, (0, 0), (10, 1)),
            (3, 20, (0, 0), (3, 3)),
            (10, 20, (0, 0), (10, 10)),
            (10, 21, (0, 0), (10, 10)),
            (2, 1, (2, 0), (2, 1)),
            (2, 1, (1, 0), (2, 0)),
            (2, 2, (1, 0), (2, 1)),
            (3, 1, (3, 1), (3, 2)),
            (3, 3, (3, 1), (3, 3)),
            (1000, 5, (999, 0), (1000, 4)),
            (1000, 5, (0, 0), (5, 0)),
            (1000, 5, (1000, 0), (1000, 5)),
        ],
    )
    def test__add_exceptions(self, limit, in_e, start_e, end_e):
        """
        Test that the _add_exceptions function properly updates the
        _oldest_exceptions and _newest_exceptions lists
        Args:
          - limit: the _exception_list_limit representing the max size of either list
          - in_e: size of list of exceptions to send to _add_exceptions
          - start_e: a tuple of ints representing the initial sizes of _oldest_exceptions and _newest_exceptions
          - end_e: a tuple of ints representing the expected sizes of _oldest_exceptions and _newest_exceptions
        """
        from collections import deque

        input_list = [RuntimeError(f"mock {i}") for i in range(in_e)]
        mock_batcher = mock.Mock()
        mock_batcher._oldest_exceptions = [
            RuntimeError(f"starting mock {i}") for i in range(start_e[0])
        ]
        mock_batcher._newest_exceptions = deque(
            [RuntimeError(f"starting mock {i}") for i in range(start_e[1])],
            maxlen=limit,
        )
        mock_batcher._exception_list_limit = limit
        mock_batcher._exceptions_since_last_raise = 0
        self._get_target_class()._add_exceptions(mock_batcher, input_list)
        assert len(mock_batcher._oldest_exceptions) == end_e[0]
        assert len(mock_batcher._newest_exceptions) == end_e[1]
        assert mock_batcher._exceptions_since_last_raise == in_e
        oldest_list_diff = end_e[0] - start_e[0]
        newest_list_diff = min(max(in_e - oldest_list_diff, 0), limit)
        for i in range(oldest_list_diff):
            assert mock_batcher._oldest_exceptions[i + start_e[0]] == input_list[i]
        for i in range(1, newest_list_diff + 1):
            assert mock_batcher._newest_exceptions[-i] == input_list[-i]

    @pytest.mark.parametrize(
        "input_retryables,expected_retryables",
        [
            (
                TABLE_DEFAULT.READ_ROWS,
                [
                    core_exceptions.DeadlineExceeded,
                    core_exceptions.ServiceUnavailable,
                    core_exceptions.Aborted,
                ],
            ),
            (
                TABLE_DEFAULT.DEFAULT,
                [core_exceptions.DeadlineExceeded, core_exceptions.ServiceUnavailable],
            ),
            (
                TABLE_DEFAULT.MUTATE_ROWS,
                [core_exceptions.DeadlineExceeded, core_exceptions.ServiceUnavailable],
            ),
            ([], []),
            ([4], [core_exceptions.DeadlineExceeded]),
        ],
    )
    def test_customizable_retryable_errors(self, input_retryables, expected_retryables):
        """
        Test that retryable functions support user-configurable arguments, and that the configured retryables are passed
        down to the gapic layer.
        """
        from google.cloud.bigtable.data._async.client import TableAsync

        with mock.patch(
            "google.api_core.retry.if_exception_type"
        ) as predicate_builder_mock:
            with mock.patch(
                "google.api_core.retry.retry_target_async"
            ) as retry_fn_mock:
                table = None
                with mock.patch("asyncio.create_task"):
                    table = TableAsync(mock.Mock(), "instance", "table")
                with self._make_one(
                    table, batch_retryable_errors=input_retryables
                ) as instance:
                    assert instance._retryable_errors == expected_retryables
                    expected_predicate = lambda a: a in expected_retryables
                    predicate_builder_mock.return_value = expected_predicate
                    retry_fn_mock.side_effect = RuntimeError("stop early")
                    mutation = self._make_mutation(count=1, size=1)
                    instance._execute_mutate_rows([mutation])
                    predicate_builder_mock.assert_called_once_with(
                        *expected_retryables, _MutateRowsIncomplete
                    )
                    retry_call_args = retry_fn_mock.call_args_list[0].args
                    assert retry_call_args[1] is expected_predicate
