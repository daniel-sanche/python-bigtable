# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# This file is automatically generated by sync_surface_generator.py. Do not edit.


from __future__ import annotations
from abc import ABC
from unittest import mock
import asyncio
import grpc
import mock
import pytest
import re
import time

from google.api_core import exceptions as core_exceptions
from google.api_core import grpc_helpers
from google.auth.credentials import AnonymousCredentials
from google.cloud.bigtable.data import TABLE_DEFAULT
from google.cloud.bigtable.data import Table
from google.cloud.bigtable.data import mutations
from google.cloud.bigtable.data.exceptions import _MutateRowsIncomplete
from google.cloud.bigtable.data.read_rows_query import ReadRowsQuery
from google.cloud.bigtable_v2.services.bigtable.client import BigtableClient
from google.cloud.bigtable_v2.services.bigtable.transports.pooled_grpc import (
    PooledBigtableGrpcTransport,
)
from google.cloud.bigtable_v2.services.bigtable.transports.pooled_grpc import (
    PooledChannel,
)
import google.api_core.exceptions as core_exceptions


class TestBigtableDataClient(ABC):
    @staticmethod
    def _get_target_class():
        from google.cloud.bigtable.data._sync.client import BigtableDataClient

        return BigtableDataClient

    @classmethod
    def _make_client(cls, *args, use_emulator=True, **kwargs):
        import os

        env_mask = {}
        if use_emulator:
            env_mask["BIGTABLE_EMULATOR_HOST"] = "localhost"
            import warnings

            warnings.filterwarnings("ignore", category=RuntimeWarning)
        else:
            kwargs["credentials"] = kwargs.get("credentials", AnonymousCredentials())
            kwargs["project"] = kwargs.get("project", "project-id")
        with mock.patch.dict(os.environ, env_mask):
            return cls._get_target_class()(*args, **kwargs)

    @property
    def is_async(self):
        return False

    def test_ctor(self):
        expected_project = "project-id"
        expected_pool_size = 11
        expected_credentials = AnonymousCredentials()
        client = self._make_client(
            project="project-id",
            pool_size=expected_pool_size,
            credentials=expected_credentials,
            use_emulator=False,
        )
        time.sleep(0)
        assert client.project == expected_project
        assert len(client.transport._grpc_channel._pool) == expected_pool_size
        assert not client._active_instances
        assert len(client._channel_refresh_tasks) == expected_pool_size
        assert client.transport._credentials == expected_credentials
        client.close()

    def test_ctor_super_inits(self):
        from google.cloud.client import ClientWithProject
        from google.api_core import client_options as client_options_lib
        from google.cloud.bigtable import __version__ as bigtable_version

        project = "project-id"
        pool_size = 11
        credentials = AnonymousCredentials()
        client_options = {"api_endpoint": "foo.bar:1234"}
        options_parsed = client_options_lib.from_dict(client_options)
        asyncio_portion = "-async" if self.is_async else ""
        transport_str = f"bt-{bigtable_version}-data{asyncio_portion}-{pool_size}"
        with mock.patch.object(BigtableClient, "__init__") as bigtable_client_init:
            bigtable_client_init.return_value = None
            with mock.patch.object(
                ClientWithProject, "__init__"
            ) as client_project_init:
                client_project_init.return_value = None
                try:
                    self._make_client(
                        project=project,
                        pool_size=pool_size,
                        credentials=credentials,
                        client_options=options_parsed,
                        use_emulator=False,
                    )
                except AttributeError:
                    pass
                assert bigtable_client_init.call_count == 1
                kwargs = bigtable_client_init.call_args[1]
                assert kwargs["transport"] == transport_str
                assert kwargs["credentials"] == credentials
                assert kwargs["client_options"] == options_parsed
                assert client_project_init.call_count == 1
                kwargs = client_project_init.call_args[1]
                assert kwargs["project"] == project
                assert kwargs["credentials"] == credentials
                assert kwargs["client_options"] == options_parsed

    def test_ctor_dict_options(self):
        from google.api_core.client_options import ClientOptions

        client_options = {"api_endpoint": "foo.bar:1234"}
        with mock.patch.object(BigtableClient, "__init__") as bigtable_client_init:
            try:
                self._make_client(client_options=client_options)
            except TypeError:
                pass
            bigtable_client_init.assert_called_once()
            kwargs = bigtable_client_init.call_args[1]
            called_options = kwargs["client_options"]
            assert called_options.api_endpoint == "foo.bar:1234"
            assert isinstance(called_options, ClientOptions)
        with mock.patch.object(
            self._get_target_class(), "_start_background_channel_refresh"
        ) as start_background_refresh:
            client = self._make_client(
                client_options=client_options, use_emulator=False
            )
            start_background_refresh.assert_called_once()
            client.close()

    def test_veneer_grpc_headers(self):
        client_component = "data-async" if self.is_async else "data"
        VENEER_HEADER_REGEX = re.compile(
            "gapic\\/[0-9]+\\.[\\w.-]+ gax\\/[0-9]+\\.[\\w.-]+ gccl\\/[0-9]+\\.[\\w.-]+-"
            + client_component
            + " gl-python\\/[0-9]+\\.[\\w.-]+ grpc\\/[0-9]+\\.[\\w.-]+"
        )
        if self.is_async:
            patch = mock.patch("google.api_core.gapic_v1.method_async.wrap_method")
        else:
            patch = mock.patch("google.api_core.gapic_v1.method.wrap_method")
        with patch as gapic_mock:
            client = self._make_client(project="project-id")
            wrapped_call_list = gapic_mock.call_args_list
            assert len(wrapped_call_list) > 0
            for call in wrapped_call_list:
                client_info = call.kwargs["client_info"]
                assert client_info is not None, f"{call} has no client_info"
                wrapped_user_agent_sorted = " ".join(
                    sorted(client_info.to_user_agent().split(" "))
                )
                assert VENEER_HEADER_REGEX.match(
                    wrapped_user_agent_sorted
                ), f"'{wrapped_user_agent_sorted}' does not match {VENEER_HEADER_REGEX}"
            client.close()

    def test_channel_pool_creation(self):
        pool_size = 14
        with mock.patch.object(
            grpc_helpers, "create_channel", mock.Mock()
        ) as create_channel:
            client = self._make_client(project="project-id", pool_size=pool_size)
            assert create_channel.call_count == pool_size
            client.close()
        client = self._make_client(project="project-id", pool_size=pool_size)
        pool_list = list(client.transport._grpc_channel._pool)
        pool_set = set(client.transport._grpc_channel._pool)
        assert len(pool_list) == len(pool_set)
        client.close()

    def test_channel_pool_rotation(self):
        pool_size = 7
        with mock.patch.object(PooledChannel, "next_channel") as next_channel:
            client = self._make_client(project="project-id", pool_size=pool_size)
            assert len(client.transport._grpc_channel._pool) == pool_size
            next_channel.reset_mock()
            with mock.patch.object(
                type(client.transport._grpc_channel._pool[0]), "unary_unary"
            ) as unary_unary:
                channel_next = None
                for i in range(pool_size):
                    channel_last = channel_next
                    channel_next = client.transport.grpc_channel._pool[i]
                    assert channel_last != channel_next
                    next_channel.return_value = channel_next
                    client.transport.ping_and_warm()
                    assert next_channel.call_count == i + 1
                    unary_unary.assert_called_once()
                    unary_unary.reset_mock()
        client.close()

    def test_channel_pool_replace(self):
        import time

        sleep_module = asyncio if self.is_async else time
        with mock.patch.object(sleep_module, "sleep"):
            pool_size = 7
            client = self._make_client(project="project-id", pool_size=pool_size)
            for replace_idx in range(pool_size):
                start_pool = [
                    channel for channel in client.transport._grpc_channel._pool
                ]
                grace_period = 9
                with mock.patch.object(
                    type(client.transport._grpc_channel._pool[-1]), "close"
                ) as close:
                    new_channel = client.transport.create_channel()
                    client.transport.replace_channel(
                        replace_idx, grace=grace_period, new_channel=new_channel
                    )
                    close.assert_called_once()
                    if self.is_async:
                        close.assert_called_once_with(grace=grace_period)
                        close.assert_called_once()
                assert client.transport._grpc_channel._pool[replace_idx] == new_channel
                for i in range(pool_size):
                    if i != replace_idx:
                        assert client.transport._grpc_channel._pool[i] == start_pool[i]
                    else:
                        assert client.transport._grpc_channel._pool[i] != start_pool[i]
            client.close()

    def test__start_background_channel_refresh_tasks_exist(self):
        client = self._make_client(project="project-id", use_emulator=False)
        assert len(client._channel_refresh_tasks) > 0
        with mock.patch.object(asyncio, "create_task") as create_task:
            client._start_background_channel_refresh()
            create_task.assert_not_called()
        client.close()

    @pytest.mark.parametrize("pool_size", [1, 3, 7])
    def test__start_background_channel_refresh(self, pool_size):
        import concurrent.futures

        with mock.patch.object(
            self._get_target_class(), "_ping_and_warm_instances", mock.Mock()
        ) as ping_and_warm:
            client = self._make_client(
                project="project-id", pool_size=pool_size, use_emulator=False
            )
            client._start_background_channel_refresh()
            assert len(client._channel_refresh_tasks) == pool_size
            for task in client._channel_refresh_tasks:
                if self.is_async:
                    assert isinstance(task, asyncio.Task)
                else:
                    assert isinstance(task, concurrent.futures.Future)
            time.sleep(0.1)
            assert ping_and_warm.call_count == pool_size
            for channel in client.transport._grpc_channel._pool:
                ping_and_warm.assert_any_call(channel)
        client.close()

    def test__ping_and_warm_instances(self):
        """test ping and warm with mocked asyncio.gather"""
        client_mock = mock.Mock()
        client_mock._execute_ping_and_warms = (
            lambda *args: self._get_target_class()._execute_ping_and_warms(
                client_mock, *args
            )
        )
        gather_tuple = (
            (asyncio, "gather") if self.is_async else (client_mock._executor, "submit")
        )
        with mock.patch.object(*gather_tuple, mock.Mock()) as gather:
            if self.is_async:
                gather.side_effect = lambda *args, **kwargs: [None for _ in args]
            else:
                gather.side_effect = lambda fn, **kwargs: [fn(**kwargs)]
            channel = mock.Mock()
            client_mock._active_instances = []
            result = self._get_target_class()._ping_and_warm_instances(
                client_mock, channel
            )
            assert len(result) == 0
            if self.is_async:
                assert gather.call_args.kwargs == {"return_exceptions": True}
            client_mock._active_instances = [
                (mock.Mock(), mock.Mock(), mock.Mock())
            ] * 4
            gather.reset_mock()
            channel.reset_mock()
            result = self._get_target_class()._ping_and_warm_instances(
                client_mock, channel
            )
            assert len(result) == 4
            if self.is_async:
                gather.assert_called_once()
                gather.assert_called_once()
                assert len(gather.call_args.args) == 4
            else:
                assert gather.call_count == 4
            grpc_call_args = channel.unary_unary().call_args_list
            for idx, (_, kwargs) in enumerate(grpc_call_args):
                (
                    expected_instance,
                    expected_table,
                    expected_app_profile,
                ) = client_mock._active_instances[idx]
                request = kwargs["request"]
                assert request["name"] == expected_instance
                assert request["app_profile_id"] == expected_app_profile
                metadata = kwargs["metadata"]
                assert len(metadata) == 1
                assert metadata[0][0] == "x-goog-request-params"
                assert (
                    metadata[0][1]
                    == f"name={expected_instance}&app_profile_id={expected_app_profile}"
                )

    def test__ping_and_warm_single_instance(self):
        """should be able to call ping and warm with single instance"""
        client_mock = mock.Mock()
        client_mock._execute_ping_and_warms = (
            lambda *args: self._get_target_class()._execute_ping_and_warms(
                client_mock, *args
            )
        )
        gather_tuple = (
            (asyncio, "gather") if self.is_async else (client_mock._executor, "submit")
        )
        with mock.patch.object(*gather_tuple, mock.Mock()) as gather:
            gather.side_effect = lambda *args, **kwargs: [mock.Mock() for _ in args]
            if self.is_async:
                gather.side_effect = lambda *args, **kwargs: [None for _ in args]
            else:
                gather.side_effect = lambda fn, **kwargs: [fn(**kwargs)]
            channel = mock.Mock()
            client_mock._active_instances = [mock.Mock()] * 100
            test_key = ("test-instance", "test-table", "test-app-profile")
            result = self._get_target_class()._ping_and_warm_instances(
                client_mock, channel, test_key
            )
            assert len(result) == 1
            grpc_call_args = channel.unary_unary().call_args_list
            assert len(grpc_call_args) == 1
            kwargs = grpc_call_args[0][1]
            request = kwargs["request"]
            assert request["name"] == "test-instance"
            assert request["app_profile_id"] == "test-app-profile"
            metadata = kwargs["metadata"]
            assert len(metadata) == 1
            assert metadata[0][0] == "x-goog-request-params"
            assert (
                metadata[0][1] == "name=test-instance&app_profile_id=test-app-profile"
            )

    @pytest.mark.parametrize(
        "refresh_interval, wait_time, expected_sleep",
        [(0, 0, 0), (0, 1, 0), (10, 0, 10), (10, 5, 5), (10, 10, 0), (10, 15, 0)],
    )
    def test__manage_channel_first_sleep(
        self, refresh_interval, wait_time, expected_sleep
    ):
        import threading
        import time

        with mock.patch.object(time, "monotonic") as monotonic:
            monotonic.return_value = 0
            sleep_tuple = (
                (asyncio, "sleep") if self.is_async else (threading.Event, "wait")
            )
            with mock.patch.object(*sleep_tuple) as sleep:
                sleep.side_effect = asyncio.CancelledError
                try:
                    client = self._make_client(project="project-id")
                    client._channel_init_time = -wait_time
                    client._manage_channel(0, refresh_interval, refresh_interval)
                except asyncio.CancelledError:
                    pass
                sleep.assert_called_once()
                call_time = sleep.call_args[0][0]
                assert (
                    abs(call_time - expected_sleep) < 0.1
                ), f"refresh_interval: {refresh_interval}, wait_time: {wait_time}, expected_sleep: {expected_sleep}"
                client.close()

    def test__manage_channel_ping_and_warm(self):
        """_manage channel should call ping and warm internally"""
        import time
        import threading

        client_mock = mock.Mock()
        client_mock._is_closed.is_set.return_value = False
        client_mock._channel_init_time = time.monotonic()
        channel_list = [mock.Mock(), mock.Mock()]
        client_mock.transport.channels = channel_list
        new_channel = mock.Mock()
        client_mock.transport.grpc_channel._create_channel.return_value = new_channel
        sleep_tuple = (asyncio, "sleep") if self.is_async else (threading.Event, "wait")
        with mock.patch.object(*sleep_tuple):
            client_mock.transport.replace_channel.side_effect = asyncio.CancelledError
            ping_and_warm = client_mock._ping_and_warm_instances = mock.Mock()
            try:
                channel_idx = 1
                self._get_target_class()._manage_channel(client_mock, channel_idx, 10)
            except asyncio.CancelledError:
                pass
            assert ping_and_warm.call_count == 2
            assert client_mock.transport.replace_channel.call_count == 1
            old_channel = channel_list[channel_idx]
            assert old_channel != new_channel
            called_with = [call[0][0] for call in ping_and_warm.call_args_list]
            assert old_channel in called_with
            assert new_channel in called_with
            ping_and_warm.reset_mock()
            try:
                self._get_target_class()._manage_channel(client_mock, 0, 0, 0)
            except asyncio.CancelledError:
                pass
            ping_and_warm.assert_called_once_with(new_channel)

    @pytest.mark.parametrize(
        "refresh_interval, num_cycles, expected_sleep",
        [(None, 1, 60 * 35), (10, 10, 100), (10, 1, 10)],
    )
    def test__manage_channel_sleeps(self, refresh_interval, num_cycles, expected_sleep):
        import time
        import random
        import threading

        channel_idx = 1
        with mock.patch.object(random, "uniform") as uniform:
            uniform.side_effect = lambda min_, max_: min_
            with mock.patch.object(time, "time") as time_mock:
                time_mock.return_value = 0
                sleep_tuple = (
                    (asyncio, "sleep") if self.is_async else (threading.Event, "wait")
                )
                with mock.patch.object(*sleep_tuple) as sleep:
                    sleep.side_effect = [None for i in range(num_cycles - 1)] + [
                        asyncio.CancelledError
                    ]
                    client = self._make_client(project="project-id")
                    with mock.patch.object(client.transport, "replace_channel"):
                        try:
                            if refresh_interval is not None:
                                client._manage_channel(
                                    channel_idx, refresh_interval, refresh_interval
                                )
                            else:
                                client._manage_channel(channel_idx)
                        except asyncio.CancelledError:
                            pass
                    assert sleep.call_count == num_cycles
                    total_sleep = sum([call[0][0] for call in sleep.call_args_list])
                    assert (
                        abs(total_sleep - expected_sleep) < 0.1
                    ), f"refresh_interval={refresh_interval}, num_cycles={num_cycles}, expected_sleep={expected_sleep}"
        client.close()

    def test__manage_channel_random(self):
        import random
        import threading

        sleep_tuple = (asyncio, "sleep") if self.is_async else (threading.Event, "wait")
        with mock.patch.object(*sleep_tuple) as sleep:
            with mock.patch.object(random, "uniform") as uniform:
                uniform.return_value = 0
                try:
                    uniform.side_effect = asyncio.CancelledError
                    client = self._make_client(project="project-id", pool_size=1)
                except asyncio.CancelledError:
                    uniform.side_effect = None
                    uniform.reset_mock()
                    sleep.reset_mock()
                min_val = 200
                max_val = 205
                uniform.side_effect = lambda min_, max_: min_
                sleep.side_effect = [None, None, asyncio.CancelledError]
                try:
                    with mock.patch.object(client.transport, "replace_channel"):
                        client._manage_channel(0, min_val, max_val)
                except asyncio.CancelledError:
                    pass
                assert uniform.call_count == 3
                uniform_args = [call[0] for call in uniform.call_args_list]
                for found_min, found_max in uniform_args:
                    assert found_min == min_val
                    assert found_max == max_val

    @pytest.mark.parametrize("num_cycles", [0, 1, 10, 100])
    def test__manage_channel_refresh(self, num_cycles):
        import threading

        expected_grace = 9
        expected_refresh = 0.5
        channel_idx = 1
        grpc_lib = grpc.aio if self.is_async else grpc
        new_channel = grpc_lib.insecure_channel("localhost:8080")
        with mock.patch.object(
            PooledBigtableGrpcTransport, "replace_channel"
        ) as replace_channel:
            sleep_tuple = (
                (asyncio, "sleep") if self.is_async else (threading.Event, "wait")
            )
            with mock.patch.object(*sleep_tuple) as sleep:
                sleep.side_effect = [None for i in range(num_cycles)] + [
                    asyncio.CancelledError
                ]
                with mock.patch.object(
                    grpc_helpers, "create_channel"
                ) as create_channel:
                    create_channel.return_value = new_channel
                    with mock.patch.object(
                        self._get_target_class(), "_start_background_channel_refresh"
                    ):
                        client = self._make_client(
                            project="project-id", use_emulator=False
                        )
                    create_channel.reset_mock()
                    try:
                        client._manage_channel(
                            channel_idx,
                            refresh_interval_min=expected_refresh,
                            refresh_interval_max=expected_refresh,
                            grace_period=expected_grace,
                        )
                    except asyncio.CancelledError:
                        pass
                    assert sleep.call_count == num_cycles + 1
                    assert create_channel.call_count == num_cycles
                    assert replace_channel.call_count == num_cycles
                    for call in replace_channel.call_args_list:
                        (args, kwargs) = call
                        assert args[0] == channel_idx
                        assert kwargs["grace"] == expected_grace
                        assert kwargs["new_channel"] == new_channel
                client.close()

    def test__register_instance(self):
        """test instance registration"""
        client_mock = mock.Mock()
        client_mock._gapic_client.instance_path.side_effect = lambda a, b: f"prefix/{b}"
        active_instances = set()
        instance_owners = {}
        client_mock._active_instances = active_instances
        client_mock._instance_owners = instance_owners
        client_mock._channel_refresh_tasks = []
        client_mock._start_background_channel_refresh.side_effect = (
            lambda: client_mock._channel_refresh_tasks.append(mock.Mock)
        )
        mock_channels = [mock.Mock() for i in range(5)]
        client_mock.transport.channels = mock_channels
        client_mock._ping_and_warm_instances = mock.Mock()
        table_mock = mock.Mock()
        self._get_target_class()._register_instance(
            client_mock, "instance-1", table_mock
        )
        assert client_mock._start_background_channel_refresh.call_count == 1
        expected_key = (
            "prefix/instance-1",
            table_mock.table_name,
            table_mock.app_profile_id,
        )
        assert len(active_instances) == 1
        assert expected_key == tuple(list(active_instances)[0])
        assert len(instance_owners) == 1
        assert expected_key == tuple(list(instance_owners)[0])
        assert client_mock._channel_refresh_tasks
        table_mock2 = mock.Mock()
        self._get_target_class()._register_instance(
            client_mock, "instance-2", table_mock2
        )
        assert client_mock._start_background_channel_refresh.call_count == 1
        assert client_mock._ping_and_warm_instances.call_count == len(mock_channels)
        for channel in mock_channels:
            assert channel in [
                call[0][0]
                for call in client_mock._ping_and_warm_instances.call_args_list
            ]
        assert len(active_instances) == 2
        assert len(instance_owners) == 2
        expected_key2 = (
            "prefix/instance-2",
            table_mock2.table_name,
            table_mock2.app_profile_id,
        )
        assert any(
            [
                expected_key2 == tuple(list(active_instances)[i])
                for i in range(len(active_instances))
            ]
        )
        assert any(
            [
                expected_key2 == tuple(list(instance_owners)[i])
                for i in range(len(instance_owners))
            ]
        )

    @pytest.mark.parametrize(
        "insert_instances,expected_active,expected_owner_keys",
        [
            ([("i", "t", None)], [("i", "t", None)], [("i", "t", None)]),
            ([("i", "t", "p")], [("i", "t", "p")], [("i", "t", "p")]),
            ([("1", "t", "p"), ("1", "t", "p")], [("1", "t", "p")], [("1", "t", "p")]),
            (
                [("1", "t", "p"), ("2", "t", "p")],
                [("1", "t", "p"), ("2", "t", "p")],
                [("1", "t", "p"), ("2", "t", "p")],
            ),
        ],
    )
    def test__register_instance_state(
        self, insert_instances, expected_active, expected_owner_keys
    ):
        """test that active_instances and instance_owners are updated as expected"""
        client_mock = mock.Mock()
        client_mock._gapic_client.instance_path.side_effect = lambda a, b: b
        active_instances = set()
        instance_owners = {}
        client_mock._active_instances = active_instances
        client_mock._instance_owners = instance_owners
        client_mock._channel_refresh_tasks = []
        client_mock._start_background_channel_refresh.side_effect = (
            lambda: client_mock._channel_refresh_tasks.append(mock.Mock)
        )
        mock_channels = [mock.Mock() for i in range(5)]
        client_mock.transport.channels = mock_channels
        client_mock._ping_and_warm_instances = mock.Mock()
        table_mock = mock.Mock()
        for instance, table, profile in insert_instances:
            table_mock.table_name = table
            table_mock.app_profile_id = profile
            self._get_target_class()._register_instance(
                client_mock, instance, table_mock
            )
        assert len(active_instances) == len(expected_active)
        assert len(instance_owners) == len(expected_owner_keys)
        for expected in expected_active:
            assert any(
                [
                    expected == tuple(list(active_instances)[i])
                    for i in range(len(active_instances))
                ]
            )
        for expected in expected_owner_keys:
            assert any(
                [
                    expected == tuple(list(instance_owners)[i])
                    for i in range(len(instance_owners))
                ]
            )

    def test__remove_instance_registration(self):
        client = self._make_client(project="project-id")
        table = mock.Mock()
        client._register_instance("instance-1", table)
        client._register_instance("instance-2", table)
        assert len(client._active_instances) == 2
        assert len(client._instance_owners.keys()) == 2
        instance_1_path = client._gapic_client.instance_path(
            client.project, "instance-1"
        )
        instance_1_key = (instance_1_path, table.table_name, table.app_profile_id)
        instance_2_path = client._gapic_client.instance_path(
            client.project, "instance-2"
        )
        instance_2_key = (instance_2_path, table.table_name, table.app_profile_id)
        assert len(client._instance_owners[instance_1_key]) == 1
        assert list(client._instance_owners[instance_1_key])[0] == id(table)
        assert len(client._instance_owners[instance_2_key]) == 1
        assert list(client._instance_owners[instance_2_key])[0] == id(table)
        success = client._remove_instance_registration("instance-1", table)
        assert success
        assert len(client._active_instances) == 1
        assert len(client._instance_owners[instance_1_key]) == 0
        assert len(client._instance_owners[instance_2_key]) == 1
        assert client._active_instances == {instance_2_key}
        success = client._remove_instance_registration("fake-key", table)
        assert not success
        assert len(client._active_instances) == 1
        client.close()

    def test__multiple_table_registration(self):
        """
        registering with multiple tables with the same key should
        add multiple owners to instance_owners, but only keep one copy
        of shared key in active_instances
        """
        from google.cloud.bigtable.data._async.client import _WarmedInstanceKey

        with self._make_client(project="project-id") as client:
            with client.get_table("instance_1", "table_1") as table_1:
                instance_1_path = client._gapic_client.instance_path(
                    client.project, "instance_1"
                )
                instance_1_key = _WarmedInstanceKey(
                    instance_1_path, table_1.table_name, table_1.app_profile_id
                )
                assert len(client._instance_owners[instance_1_key]) == 1
                assert len(client._active_instances) == 1
                assert id(table_1) in client._instance_owners[instance_1_key]
                with client.get_table("instance_1", "table_1") as table_2:
                    assert len(client._instance_owners[instance_1_key]) == 2
                    assert len(client._active_instances) == 1
                    assert id(table_1) in client._instance_owners[instance_1_key]
                    assert id(table_2) in client._instance_owners[instance_1_key]
                    with client.get_table("instance_1", "table_3") as table_3:
                        instance_3_path = client._gapic_client.instance_path(
                            client.project, "instance_1"
                        )
                        instance_3_key = _WarmedInstanceKey(
                            instance_3_path, table_3.table_name, table_3.app_profile_id
                        )
                        assert len(client._instance_owners[instance_1_key]) == 2
                        assert len(client._instance_owners[instance_3_key]) == 1
                        assert len(client._active_instances) == 2
                        assert id(table_1) in client._instance_owners[instance_1_key]
                        assert id(table_2) in client._instance_owners[instance_1_key]
                        assert id(table_3) in client._instance_owners[instance_3_key]
                assert len(client._active_instances) == 1
                assert instance_1_key in client._active_instances
                assert id(table_2) not in client._instance_owners[instance_1_key]
            assert len(client._active_instances) == 0
            assert instance_1_key not in client._active_instances
            assert len(client._instance_owners[instance_1_key]) == 0

    def test__multiple_instance_registration(self):
        """
        registering with multiple instance keys should update the key
        in instance_owners and active_instances
        """
        from google.cloud.bigtable.data._async.client import _WarmedInstanceKey

        with self._make_client(project="project-id") as client:
            with client.get_table("instance_1", "table_1") as table_1:
                with client.get_table("instance_2", "table_2") as table_2:
                    instance_1_path = client._gapic_client.instance_path(
                        client.project, "instance_1"
                    )
                    instance_1_key = _WarmedInstanceKey(
                        instance_1_path, table_1.table_name, table_1.app_profile_id
                    )
                    instance_2_path = client._gapic_client.instance_path(
                        client.project, "instance_2"
                    )
                    instance_2_key = _WarmedInstanceKey(
                        instance_2_path, table_2.table_name, table_2.app_profile_id
                    )
                    assert len(client._instance_owners[instance_1_key]) == 1
                    assert len(client._instance_owners[instance_2_key]) == 1
                    assert len(client._active_instances) == 2
                    assert id(table_1) in client._instance_owners[instance_1_key]
                    assert id(table_2) in client._instance_owners[instance_2_key]
                assert len(client._active_instances) == 1
                assert instance_1_key in client._active_instances
                assert len(client._instance_owners[instance_2_key]) == 0
                assert len(client._instance_owners[instance_1_key]) == 1
                assert id(table_1) in client._instance_owners[instance_1_key]
            assert len(client._active_instances) == 0
            assert len(client._instance_owners[instance_1_key]) == 0
            assert len(client._instance_owners[instance_2_key]) == 0

    def test_get_table(self):
        from google.cloud.bigtable.data._async.client import _WarmedInstanceKey

        client = self._make_client(project="project-id")
        assert not client._active_instances
        expected_table_id = "table-id"
        expected_instance_id = "instance-id"
        expected_app_profile_id = "app-profile-id"
        table = client.get_table(
            expected_instance_id, expected_table_id, expected_app_profile_id
        )
        time.sleep(0)
        assert isinstance(table, Table)
        assert table.table_id == expected_table_id
        assert (
            table.table_name
            == f"projects/{client.project}/instances/{expected_instance_id}/tables/{expected_table_id}"
        )
        assert table.instance_id == expected_instance_id
        assert (
            table.instance_name
            == f"projects/{client.project}/instances/{expected_instance_id}"
        )
        assert table.app_profile_id == expected_app_profile_id
        assert table.client is client
        instance_key = _WarmedInstanceKey(
            table.instance_name, table.table_name, table.app_profile_id
        )
        assert instance_key in client._active_instances
        assert client._instance_owners[instance_key] == {id(table)}
        client.close()

    def test_get_table_arg_passthrough(self):
        """All arguments passed in get_table should be sent to constructor"""
        with self._make_client(project="project-id") as client:
            with mock.patch.object(
                TestTable._get_target_class(), "__init__"
            ) as mock_constructor:
                mock_constructor.return_value = None
                assert not client._active_instances
                expected_table_id = "table-id"
                expected_instance_id = "instance-id"
                expected_app_profile_id = "app-profile-id"
                expected_args = (1, "test", {"test": 2})
                expected_kwargs = {"hello": "world", "test": 2}
                client.get_table(
                    expected_instance_id,
                    expected_table_id,
                    expected_app_profile_id,
                    *expected_args,
                    **expected_kwargs,
                )
                mock_constructor.assert_called_once_with(
                    client,
                    expected_instance_id,
                    expected_table_id,
                    expected_app_profile_id,
                    *expected_args,
                    **expected_kwargs,
                )

    def test_get_table_context_manager(self):
        from google.cloud.bigtable.data._async.client import _WarmedInstanceKey

        expected_table_id = "table-id"
        expected_instance_id = "instance-id"
        expected_app_profile_id = "app-profile-id"
        expected_project_id = "project-id"
        with mock.patch.object(Table, "close") as close_mock:
            with self._make_client(project=expected_project_id) as client:
                with client.get_table(
                    expected_instance_id, expected_table_id, expected_app_profile_id
                ) as table:
                    time.sleep(0)
                    assert isinstance(table, Table)
                    assert table.table_id == expected_table_id
                    assert (
                        table.table_name
                        == f"projects/{expected_project_id}/instances/{expected_instance_id}/tables/{expected_table_id}"
                    )
                    assert table.instance_id == expected_instance_id
                    assert (
                        table.instance_name
                        == f"projects/{expected_project_id}/instances/{expected_instance_id}"
                    )
                    assert table.app_profile_id == expected_app_profile_id
                    assert table.client is client
                    instance_key = _WarmedInstanceKey(
                        table.instance_name, table.table_name, table.app_profile_id
                    )
                    assert instance_key in client._active_instances
                    assert client._instance_owners[instance_key] == {id(table)}
            assert close_mock.call_count == 1

    def test_multiple_pool_sizes(self):
        pool_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256]
        for pool_size in pool_sizes:
            client = self._make_client(
                project="project-id", pool_size=pool_size, use_emulator=False
            )
            assert len(client._channel_refresh_tasks) == pool_size
            client_duplicate = self._make_client(
                project="project-id", pool_size=pool_size, use_emulator=False
            )
            assert len(client_duplicate._channel_refresh_tasks) == pool_size
            assert str(pool_size) in str(client.transport)
            client.close()
            client_duplicate.close()

    def test_close(self):
        pool_size = 7
        client = self._make_client(
            project="project-id", pool_size=pool_size, use_emulator=False
        )
        assert len(client._channel_refresh_tasks) == pool_size
        tasks_list = list(client._channel_refresh_tasks)
        for task in client._channel_refresh_tasks:
            assert not task.done()
        with mock.patch.object(
            PooledBigtableGrpcTransport, "close", mock.Mock()
        ) as close_mock:
            client.close()
            close_mock.assert_called_once()
            close_mock.assert_called_once()
        for task in tasks_list:
            assert task.done()
        assert client._channel_refresh_tasks == []

    def test_context_manager(self):
        close_mock = mock.Mock()
        true_close = None
        with self._make_client(project="project-id") as client:
            true_close = client.close()
            client.close = close_mock
            for task in client._channel_refresh_tasks:
                assert not task.done()
            assert client.project == "project-id"
            assert client._active_instances == set()
            close_mock.assert_not_called()
        close_mock.assert_called_once()
        close_mock.assert_called_once()
        true_close


class TestTable(ABC):
    def _make_client(self, *args, **kwargs):
        return TestBigtableDataClient._make_client(*args, **kwargs)

    @staticmethod
    def _get_target_class():
        from google.cloud.bigtable.data._sync.client import Table

        return Table

    @property
    def is_async(self):
        return False

    def test_table_ctor(self):
        from google.cloud.bigtable.data._async.client import _WarmedInstanceKey

        expected_table_id = "table-id"
        expected_instance_id = "instance-id"
        expected_app_profile_id = "app-profile-id"
        expected_operation_timeout = 123
        expected_attempt_timeout = 12
        expected_read_rows_operation_timeout = 1.5
        expected_read_rows_attempt_timeout = 0.5
        expected_mutate_rows_operation_timeout = 2.5
        expected_mutate_rows_attempt_timeout = 0.75
        client = self._make_client()
        assert not client._active_instances
        table = self._get_target_class()(
            client,
            expected_instance_id,
            expected_table_id,
            expected_app_profile_id,
            default_operation_timeout=expected_operation_timeout,
            default_attempt_timeout=expected_attempt_timeout,
            default_read_rows_operation_timeout=expected_read_rows_operation_timeout,
            default_read_rows_attempt_timeout=expected_read_rows_attempt_timeout,
            default_mutate_rows_operation_timeout=expected_mutate_rows_operation_timeout,
            default_mutate_rows_attempt_timeout=expected_mutate_rows_attempt_timeout,
        )
        time.sleep(0)
        assert table.table_id == expected_table_id
        assert table.instance_id == expected_instance_id
        assert table.app_profile_id == expected_app_profile_id
        assert table.client is client
        instance_key = _WarmedInstanceKey(
            table.instance_name, table.table_name, table.app_profile_id
        )
        assert instance_key in client._active_instances
        assert client._instance_owners[instance_key] == {id(table)}
        assert table.default_operation_timeout == expected_operation_timeout
        assert table.default_attempt_timeout == expected_attempt_timeout
        assert (
            table.default_read_rows_operation_timeout
            == expected_read_rows_operation_timeout
        )
        assert (
            table.default_read_rows_attempt_timeout
            == expected_read_rows_attempt_timeout
        )
        assert (
            table.default_mutate_rows_operation_timeout
            == expected_mutate_rows_operation_timeout
        )
        assert (
            table.default_mutate_rows_attempt_timeout
            == expected_mutate_rows_attempt_timeout
        )
        table._register_instance_future
        assert table._register_instance_future.done()
        assert not table._register_instance_future.cancelled()
        assert table._register_instance_future.exception() is None
        client.close()

    def test_table_ctor_defaults(self):
        """should provide default timeout values and app_profile_id"""
        expected_table_id = "table-id"
        expected_instance_id = "instance-id"
        client = self._make_client()
        assert not client._active_instances
        table = Table(client, expected_instance_id, expected_table_id)
        time.sleep(0)
        assert table.table_id == expected_table_id
        assert table.instance_id == expected_instance_id
        assert table.app_profile_id is None
        assert table.client is client
        assert table.default_operation_timeout == 60
        assert table.default_read_rows_operation_timeout == 600
        assert table.default_mutate_rows_operation_timeout == 600
        assert table.default_attempt_timeout == 20
        assert table.default_read_rows_attempt_timeout == 20
        assert table.default_mutate_rows_attempt_timeout == 60
        client.close()

    def test_table_ctor_invalid_timeout_values(self):
        """bad timeout values should raise ValueError"""
        client = self._make_client()
        timeout_pairs = [
            ("default_operation_timeout", "default_attempt_timeout"),
            (
                "default_read_rows_operation_timeout",
                "default_read_rows_attempt_timeout",
            ),
            (
                "default_mutate_rows_operation_timeout",
                "default_mutate_rows_attempt_timeout",
            ),
        ]
        for operation_timeout, attempt_timeout in timeout_pairs:
            with pytest.raises(ValueError) as e:
                Table(client, "", "", **{attempt_timeout: -1})
            assert "attempt_timeout must be greater than 0" in str(e.value)
            with pytest.raises(ValueError) as e:
                Table(client, "", "", **{operation_timeout: -1})
            assert "operation_timeout must be greater than 0" in str(e.value)
        client.close()

    @pytest.mark.parametrize(
        "fn_name,fn_args,is_stream,extra_retryables",
        [
            ("read_rows_stream", (ReadRowsQuery(),), True, ()),
            ("read_rows", (ReadRowsQuery(),), True, ()),
            ("read_row", (b"row_key",), True, ()),
            ("read_rows_sharded", ([ReadRowsQuery()],), True, ()),
            ("row_exists", (b"row_key",), True, ()),
            ("sample_row_keys", (), False, ()),
            ("mutate_row", (b"row_key", [mock.Mock()]), False, ()),
            (
                "bulk_mutate_rows",
                ([mutations.RowMutationEntry(b"key", [mutations.DeleteAllFromRow()])],),
                False,
                (_MutateRowsIncomplete,),
            ),
        ],
    )
    @pytest.mark.parametrize(
        "input_retryables,expected_retryables",
        [
            (
                TABLE_DEFAULT.READ_ROWS,
                [
                    core_exceptions.DeadlineExceeded,
                    core_exceptions.ServiceUnavailable,
                    core_exceptions.Aborted,
                ],
            ),
            (
                TABLE_DEFAULT.DEFAULT,
                [core_exceptions.DeadlineExceeded, core_exceptions.ServiceUnavailable],
            ),
            (
                TABLE_DEFAULT.MUTATE_ROWS,
                [core_exceptions.DeadlineExceeded, core_exceptions.ServiceUnavailable],
            ),
            ([], []),
            ([4], [core_exceptions.DeadlineExceeded]),
        ],
    )
    def test_customizable_retryable_errors(
        self,
        input_retryables,
        expected_retryables,
        fn_name,
        fn_args,
        is_stream,
        extra_retryables,
    ):
        """
        Test that retryable functions support user-configurable arguments, and that the configured retryables are passed
        down to the gapic layer.
        """
        retry_fn = "retry_target"
        if is_stream:
            retry_fn += "_stream"
        if self.is_async:
            retry_fn += "_async"
        with mock.patch(f"google.api_core.retry.{retry_fn}") as retry_fn_mock:
            with self._make_client() as client:
                table = client.get_table("instance-id", "table-id")
                expected_predicate = lambda a: a in expected_retryables
                retry_fn_mock.side_effect = RuntimeError("stop early")
                with mock.patch(
                    "google.api_core.retry.if_exception_type"
                ) as predicate_builder_mock:
                    predicate_builder_mock.return_value = expected_predicate
                    with pytest.raises(Exception):
                        test_fn = table.__getattribute__(fn_name)
                        test_fn(*fn_args, retryable_errors=input_retryables)
                    predicate_builder_mock.assert_called_once_with(
                        *expected_retryables, *extra_retryables
                    )
                    retry_call_args = retry_fn_mock.call_args_list[0].args
                    assert retry_call_args[1] is expected_predicate

    @pytest.mark.parametrize(
        "fn_name,fn_args,gapic_fn",
        [
            ("read_rows_stream", (ReadRowsQuery(),), "read_rows"),
            ("read_rows", (ReadRowsQuery(),), "read_rows"),
            ("read_row", (b"row_key",), "read_rows"),
            ("read_rows_sharded", ([ReadRowsQuery()],), "read_rows"),
            ("row_exists", (b"row_key",), "read_rows"),
            ("sample_row_keys", (), "sample_row_keys"),
            ("mutate_row", (b"row_key", [mock.Mock()]), "mutate_row"),
            (
                "bulk_mutate_rows",
                ([mutations.RowMutationEntry(b"key", [mutations.DeleteAllFromRow()])],),
                "mutate_rows",
            ),
            ("check_and_mutate_row", (b"row_key", None), "check_and_mutate_row"),
            (
                "read_modify_write_row",
                (b"row_key", mock.Mock()),
                "read_modify_write_row",
            ),
        ],
    )
    @pytest.mark.parametrize("include_app_profile", [True, False])
    def test_call_metadata(self, include_app_profile, fn_name, fn_args, gapic_fn):
        """check that all requests attach proper metadata headers"""
        profile = "profile" if include_app_profile else None
        with mock.patch.object(
            BigtableClient, gapic_fn, mock.mock.Mock()
        ) as gapic_mock:
            gapic_mock.side_effect = RuntimeError("stop early")
            with self._make_client() as client:
                table = Table(client, "instance-id", "table-id", profile)
                try:
                    test_fn = table.__getattribute__(fn_name)
                    maybe_stream = test_fn(*fn_args)
                    [i for i in maybe_stream]
                except Exception:
                    pass
                kwargs = gapic_mock.call_args_list[0].kwargs
                metadata = kwargs["metadata"]
                goog_metadata = None
                for key, value in metadata:
                    if key == "x-goog-request-params":
                        goog_metadata = value
                assert goog_metadata is not None, "x-goog-request-params not found"
                assert "table_name=" + table.table_name in goog_metadata
                if include_app_profile:
                    assert "app_profile_id=profile" in goog_metadata
                else:
                    assert "app_profile_id=" not in goog_metadata
