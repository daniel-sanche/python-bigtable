# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# This file is automatically generated by sync_surface_generator.py. Do not edit.


from abc import ABC
from tests.unit.data._async.test__mutate_rows import TestMutateRowsOperation
from tests.unit.data._async.test__read_rows import TestReadRowsOperation
from unittest import mock
import mock
import pytest

from google.cloud.bigtable_v2.types import MutateRowsResponse
from google.rpc import status_pb2
import google.api_core.exceptions as core_exceptions


class TestMutateRowsOperation(ABC):
    def _target_class(self):
        from google.cloud.bigtable.data._sync._mutate_rows import _MutateRowsOperation

        return _MutateRowsOperation

    def _make_one(self, *args, **kwargs):
        if not args:
            kwargs["gapic_client"] = kwargs.pop("gapic_client", mock.Mock())
            kwargs["table"] = kwargs.pop("table", mock.Mock())
            kwargs["operation_timeout"] = kwargs.pop("operation_timeout", 5)
            kwargs["attempt_timeout"] = kwargs.pop("attempt_timeout", 0.1)
            kwargs["retryable_exceptions"] = kwargs.pop("retryable_exceptions", ())
            kwargs["mutation_entries"] = kwargs.pop("mutation_entries", [])
        return self._target_class()(*args, **kwargs)

    def _make_mutation(self, count=1, size=1):
        mutation = mock.Mock()
        mutation.size.return_value = size
        mutation.mutations = [mock.Mock()] * count
        return mutation

    def _mock_stream(self, mutation_list, error_dict):
        for idx, entry in enumerate(mutation_list):
            code = error_dict.get(idx, 0)
            yield MutateRowsResponse(
                entries=[
                    MutateRowsResponse.Entry(
                        index=idx, status=status_pb2.Status(code=code)
                    )
                ]
            )

    def _make_mock_gapic(self, mutation_list, error_dict=None):
        mock_fn = mock.Mock()
        if error_dict is None:
            error_dict = {}
        mock_fn.side_effect = lambda *args, **kwargs: self._mock_stream(
            mutation_list, error_dict
        )
        return mock_fn

    def test_ctor(self):
        """test that constructor sets all the attributes correctly"""
        from google.cloud.bigtable.data._async._mutate_rows import _EntryWithProto
        from google.cloud.bigtable.data.exceptions import _MutateRowsIncomplete
        from google.api_core.exceptions import DeadlineExceeded
        from google.api_core.exceptions import Aborted

        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation(), self._make_mutation()]
        operation_timeout = 0.05
        attempt_timeout = 0.01
        retryable_exceptions = ()
        instance = self._make_one(
            client,
            table,
            entries,
            operation_timeout,
            attempt_timeout,
            retryable_exceptions,
        )
        assert client.mutate_rows.call_count == 0
        instance._gapic_fn()
        assert client.mutate_rows.call_count == 1
        inner_kwargs = client.mutate_rows.call_args[1]
        assert len(inner_kwargs) == 4
        assert inner_kwargs["table_name"] == table.table_name
        assert inner_kwargs["app_profile_id"] == table.app_profile_id
        assert inner_kwargs["retry"] is None
        metadata = inner_kwargs["metadata"]
        assert len(metadata) == 1
        assert metadata[0][0] == "x-goog-request-params"
        assert str(table.table_name) in metadata[0][1]
        assert str(table.app_profile_id) in metadata[0][1]
        entries_w_pb = [_EntryWithProto(e, e._to_pb()) for e in entries]
        assert instance.mutations == entries_w_pb
        assert next(instance.timeout_generator) == attempt_timeout
        assert instance.is_retryable is not None
        assert instance.is_retryable(DeadlineExceeded("")) is False
        assert instance.is_retryable(Aborted("")) is False
        assert instance.is_retryable(_MutateRowsIncomplete("")) is True
        assert instance.is_retryable(RuntimeError("")) is False
        assert instance.remaining_indices == list(range(len(entries)))
        assert instance.errors == {}

    def test_ctor_too_many_entries(self):
        """should raise an error if an operation is created with more than 100,000 entries"""
        from google.cloud.bigtable.data._async._mutate_rows import (
            _MUTATE_ROWS_REQUEST_MUTATION_LIMIT,
        )

        assert _MUTATE_ROWS_REQUEST_MUTATION_LIMIT == 100000
        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation()] * _MUTATE_ROWS_REQUEST_MUTATION_LIMIT
        operation_timeout = 0.05
        attempt_timeout = 0.01
        self._make_one(client, table, entries, operation_timeout, attempt_timeout)
        with pytest.raises(ValueError) as e:
            self._make_one(
                client,
                table,
                entries + [self._make_mutation()],
                operation_timeout,
                attempt_timeout,
            )
        assert "mutate_rows requests can contain at most 100000 mutations" in str(
            e.value
        )
        assert "Found 100001" in str(e.value)

    def test_mutate_rows_operation(self):
        """Test successful case of mutate_rows_operation"""
        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation(), self._make_mutation()]
        operation_timeout = 0.05
        cls = self._target_class()
        with mock.patch(
            f"{cls.__module__}.{cls.__name__}._run_attempt", mock.Mock()
        ) as attempt_mock:
            instance = self._make_one(
                client, table, entries, operation_timeout, operation_timeout
            )
            instance.start()
            assert attempt_mock.call_count == 1

    @pytest.mark.parametrize(
        "exc_type", [RuntimeError, ZeroDivisionError, core_exceptions.Forbidden]
    )
    def test_mutate_rows_attempt_exception(self, exc_type):
        """exceptions raised from attempt should be raised in MutationsExceptionGroup"""
        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation(), self._make_mutation()]
        operation_timeout = 0.05
        expected_exception = exc_type("test")
        client.mutate_rows.side_effect = expected_exception
        found_exc = None
        try:
            instance = self._make_one(
                client, table, entries, operation_timeout, operation_timeout
            )
            instance._run_attempt()
        except Exception as e:
            found_exc = e
        assert client.mutate_rows.call_count == 1
        assert type(found_exc) is exc_type
        assert found_exc == expected_exception
        assert len(instance.errors) == 2
        assert len(instance.remaining_indices) == 0

    @pytest.mark.parametrize(
        "exc_type", [RuntimeError, ZeroDivisionError, core_exceptions.Forbidden]
    )
    def test_mutate_rows_exception(self, exc_type):
        """exceptions raised from retryable should be raised in MutationsExceptionGroup"""
        from google.cloud.bigtable.data.exceptions import MutationsExceptionGroup
        from google.cloud.bigtable.data.exceptions import FailedMutationEntryError

        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation(), self._make_mutation()]
        operation_timeout = 0.05
        expected_cause = exc_type("abort")
        with mock.patch.object(
            self._target_class(), "_run_attempt", mock.Mock()
        ) as attempt_mock:
            attempt_mock.side_effect = expected_cause
            found_exc = None
            try:
                instance = self._make_one(
                    client, table, entries, operation_timeout, operation_timeout
                )
                instance.start()
            except MutationsExceptionGroup as e:
                found_exc = e
            assert attempt_mock.call_count == 1
            assert len(found_exc.exceptions) == 2
            assert isinstance(found_exc.exceptions[0], FailedMutationEntryError)
            assert isinstance(found_exc.exceptions[1], FailedMutationEntryError)
            assert found_exc.exceptions[0].__cause__ == expected_cause
            assert found_exc.exceptions[1].__cause__ == expected_cause

    @pytest.mark.parametrize(
        "exc_type", [core_exceptions.DeadlineExceeded, RuntimeError]
    )
    def test_mutate_rows_exception_retryable_eventually_pass(self, exc_type):
        """If an exception fails but eventually passes, it should not raise an exception"""
        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation()]
        operation_timeout = 1
        expected_cause = exc_type("retry")
        num_retries = 2
        with mock.patch.object(
            self._target_class(), "_run_attempt", mock.Mock()
        ) as attempt_mock:
            attempt_mock.side_effect = [expected_cause] * num_retries + [None]
            instance = self._make_one(
                client,
                table,
                entries,
                operation_timeout,
                operation_timeout,
                retryable_exceptions=(exc_type,),
            )
            instance.start()
            assert attempt_mock.call_count == num_retries + 1

    def test_mutate_rows_incomplete_ignored(self):
        """MutateRowsIncomplete exceptions should not be added to error list"""
        from google.cloud.bigtable.data.exceptions import _MutateRowsIncomplete
        from google.cloud.bigtable.data.exceptions import MutationsExceptionGroup
        from google.api_core.exceptions import DeadlineExceeded

        client = mock.Mock()
        table = mock.Mock()
        entries = [self._make_mutation()]
        operation_timeout = 0.05
        with mock.patch.object(
            self._target_class(), "_run_attempt", mock.Mock()
        ) as attempt_mock:
            attempt_mock.side_effect = _MutateRowsIncomplete("ignored")
            found_exc = None
            try:
                instance = self._make_one(
                    client, table, entries, operation_timeout, operation_timeout
                )
                instance.start()
            except MutationsExceptionGroup as e:
                found_exc = e
            assert attempt_mock.call_count > 0
            assert len(found_exc.exceptions) == 1
            assert isinstance(found_exc.exceptions[0].__cause__, DeadlineExceeded)

    def test_run_attempt_single_entry_success(self):
        """Test mutating a single entry"""
        mutation = self._make_mutation()
        expected_timeout = 1.3
        mock_gapic_fn = self._make_mock_gapic({0: mutation})
        instance = self._make_one(
            mutation_entries=[mutation], attempt_timeout=expected_timeout
        )
        with mock.patch.object(instance, "_gapic_fn", mock_gapic_fn):
            instance._run_attempt()
        assert len(instance.remaining_indices) == 0
        assert mock_gapic_fn.call_count == 1
        (_, kwargs) = mock_gapic_fn.call_args
        assert kwargs["timeout"] == expected_timeout
        assert kwargs["entries"] == [mutation._to_pb()]

    def test_run_attempt_empty_request(self):
        """Calling with no mutations should result in no API calls"""
        mock_gapic_fn = self._make_mock_gapic([])
        instance = self._make_one(mutation_entries=[])
        instance._run_attempt()
        assert mock_gapic_fn.call_count == 0

    def test_run_attempt_partial_success_retryable(self):
        """Some entries succeed, but one fails. Should report the proper index, and raise incomplete exception"""
        from google.cloud.bigtable.data.exceptions import _MutateRowsIncomplete

        success_mutation = self._make_mutation()
        success_mutation_2 = self._make_mutation()
        failure_mutation = self._make_mutation()
        mutations = [success_mutation, failure_mutation, success_mutation_2]
        mock_gapic_fn = self._make_mock_gapic(mutations, error_dict={1: 300})
        instance = self._make_one(mutation_entries=mutations)
        instance.is_retryable = lambda x: True
        with mock.patch.object(instance, "_gapic_fn", mock_gapic_fn):
            with pytest.raises(_MutateRowsIncomplete):
                instance._run_attempt()
        assert instance.remaining_indices == [1]
        assert 0 not in instance.errors
        assert len(instance.errors[1]) == 1
        assert instance.errors[1][0].grpc_status_code == 300
        assert 2 not in instance.errors

    def test_run_attempt_partial_success_non_retryable(self):
        """Some entries succeed, but one fails. Exception marked as non-retryable. Do not raise incomplete error"""
        success_mutation = self._make_mutation()
        success_mutation_2 = self._make_mutation()
        failure_mutation = self._make_mutation()
        mutations = [success_mutation, failure_mutation, success_mutation_2]
        mock_gapic_fn = self._make_mock_gapic(mutations, error_dict={1: 300})
        instance = self._make_one(mutation_entries=mutations)
        instance.is_retryable = lambda x: False
        with mock.patch.object(instance, "_gapic_fn", mock_gapic_fn):
            instance._run_attempt()
        assert instance.remaining_indices == []
        assert 0 not in instance.errors
        assert len(instance.errors[1]) == 1
        assert instance.errors[1][0].grpc_status_code == 300
        assert 2 not in instance.errors


class TestReadRowsOperation(ABC):
    """
    Tests helper functions in the ReadRowsOperation class
    in-depth merging logic in merge_row_response_stream and _read_rows_retryable_attempt
    is tested in test_read_rows_acceptance test_client_read_rows, and conformance tests
    """

    @staticmethod
    def _get_target_class():
        from google.cloud.bigtable.data._sync._read_rows import _ReadRowsOperation

        return _ReadRowsOperation

    def _make_one(self, *args, **kwargs):
        return self._get_target_class()(*args, **kwargs)

    def test_ctor(self):
        from google.cloud.bigtable.data import ReadRowsQuery

        row_limit = 91
        query = ReadRowsQuery(limit=row_limit)
        client = mock.Mock()
        client.read_rows = mock.Mock()
        client.read_rows.return_value = None
        table = mock.Mock()
        table._client = client
        table.table_name = "test_table"
        table.app_profile_id = "test_profile"
        expected_operation_timeout = 42
        expected_request_timeout = 44
        time_gen_mock = mock.Mock()
        with mock.patch(
            "google.cloud.bigtable.data._helpers._attempt_timeout_generator",
            time_gen_mock,
        ):
            instance = self._make_one(
                query,
                table,
                operation_timeout=expected_operation_timeout,
                attempt_timeout=expected_request_timeout,
            )
        assert time_gen_mock.call_count == 1
        time_gen_mock.assert_called_once_with(
            expected_request_timeout, expected_operation_timeout
        )
        assert instance._last_yielded_row_key is None
        assert instance._remaining_count == row_limit
        assert instance.operation_timeout == expected_operation_timeout
        assert client.read_rows.call_count == 0
        assert instance._metadata == [
            (
                "x-goog-request-params",
                "table_name=test_table&app_profile_id=test_profile",
            )
        ]
        assert instance.request.table_name == table.table_name
        assert instance.request.app_profile_id == table.app_profile_id
        assert instance.request.rows_limit == row_limit

    @pytest.mark.parametrize(
        "in_keys,last_key,expected",
        [
            (["b", "c", "d"], "a", ["b", "c", "d"]),
            (["a", "b", "c"], "b", ["c"]),
            (["a", "b", "c"], "c", []),
            (["a", "b", "c"], "d", []),
            (["d", "c", "b", "a"], "b", ["d", "c"]),
        ],
    )
    def test_revise_request_rowset_keys(self, in_keys, last_key, expected):
        from google.cloud.bigtable_v2.types import RowSet as RowSetPB
        from google.cloud.bigtable_v2.types import RowRange as RowRangePB

        in_keys = [key.encode("utf-8") for key in in_keys]
        expected = [key.encode("utf-8") for key in expected]
        last_key = last_key.encode("utf-8")
        sample_range = RowRangePB(start_key_open=last_key)
        row_set = RowSetPB(row_keys=in_keys, row_ranges=[sample_range])
        revised = self._get_target_class()._revise_request_rowset(row_set, last_key)
        assert revised.row_keys == expected
        assert revised.row_ranges == [sample_range]

    @pytest.mark.parametrize(
        "in_ranges,last_key,expected",
        [
            (
                [{"start_key_open": "b", "end_key_closed": "d"}],
                "a",
                [{"start_key_open": "b", "end_key_closed": "d"}],
            ),
            (
                [{"start_key_closed": "b", "end_key_closed": "d"}],
                "a",
                [{"start_key_closed": "b", "end_key_closed": "d"}],
            ),
            (
                [{"start_key_open": "a", "end_key_closed": "d"}],
                "b",
                [{"start_key_open": "b", "end_key_closed": "d"}],
            ),
            (
                [{"start_key_closed": "a", "end_key_open": "d"}],
                "b",
                [{"start_key_open": "b", "end_key_open": "d"}],
            ),
            (
                [{"start_key_closed": "b", "end_key_closed": "d"}],
                "b",
                [{"start_key_open": "b", "end_key_closed": "d"}],
            ),
            ([{"start_key_closed": "b", "end_key_closed": "d"}], "d", []),
            ([{"start_key_closed": "b", "end_key_open": "d"}], "d", []),
            ([{"start_key_closed": "b", "end_key_closed": "d"}], "e", []),
            ([{"start_key_closed": "b"}], "z", [{"start_key_open": "z"}]),
            ([{"start_key_closed": "b"}], "a", [{"start_key_closed": "b"}]),
            (
                [{"end_key_closed": "z"}],
                "a",
                [{"start_key_open": "a", "end_key_closed": "z"}],
            ),
            (
                [{"end_key_open": "z"}],
                "a",
                [{"start_key_open": "a", "end_key_open": "z"}],
            ),
        ],
    )
    def test_revise_request_rowset_ranges(self, in_ranges, last_key, expected):
        from google.cloud.bigtable_v2.types import RowSet as RowSetPB
        from google.cloud.bigtable_v2.types import RowRange as RowRangePB

        next_key = (last_key + "a").encode("utf-8")
        last_key = last_key.encode("utf-8")
        in_ranges = [
            RowRangePB(**{k: v.encode("utf-8") for (k, v) in r.items()})
            for r in in_ranges
        ]
        expected = [
            RowRangePB(**{k: v.encode("utf-8") for (k, v) in r.items()})
            for r in expected
        ]
        row_set = RowSetPB(row_ranges=in_ranges, row_keys=[next_key])
        revised = self._get_target_class()._revise_request_rowset(row_set, last_key)
        assert revised.row_keys == [next_key]
        assert revised.row_ranges == expected

    @pytest.mark.parametrize("last_key", ["a", "b", "c"])
    def test_revise_request_full_table(self, last_key):
        from google.cloud.bigtable_v2.types import RowSet as RowSetPB
        from google.cloud.bigtable_v2.types import RowRange as RowRangePB

        last_key = last_key.encode("utf-8")
        row_set = RowSetPB()
        for selected_set in [row_set, None]:
            revised = self._get_target_class()._revise_request_rowset(
                selected_set, last_key
            )
            assert revised.row_keys == []
            assert len(revised.row_ranges) == 1
            assert revised.row_ranges[0] == RowRangePB(start_key_open=last_key)

    def test_revise_to_empty_rowset(self):
        """revising to an empty rowset should raise error"""
        from google.cloud.bigtable.data.exceptions import _RowSetComplete
        from google.cloud.bigtable_v2.types import RowSet as RowSetPB
        from google.cloud.bigtable_v2.types import RowRange as RowRangePB

        row_keys = [b"a", b"b", b"c"]
        row_range = RowRangePB(end_key_open=b"c")
        row_set = RowSetPB(row_keys=row_keys, row_ranges=[row_range])
        with pytest.raises(_RowSetComplete):
            self._get_target_class()._revise_request_rowset(row_set, b"d")

    @pytest.mark.parametrize(
        "start_limit,emit_num,expected_limit",
        [
            (10, 0, 10),
            (10, 1, 9),
            (10, 10, 0),
            (None, 10, None),
            (None, 0, None),
            (4, 2, 2),
        ],
    )
    def test_revise_limit(self, start_limit, emit_num, expected_limit):
        """
        revise_limit should revise the request's limit field
        - if limit is 0 (unlimited), it should never be revised
        - if start_limit-emit_num == 0, the request should end early
        - if the number emitted exceeds the new limit, an exception should
          should be raised (tested in test_revise_limit_over_limit)
        """
        from google.cloud.bigtable.data import ReadRowsQuery
        from google.cloud.bigtable_v2.types import ReadRowsResponse

        def awaitable_stream():
            def mock_stream():
                for i in range(emit_num):
                    yield ReadRowsResponse(
                        chunks=[
                            ReadRowsResponse.CellChunk(
                                row_key=str(i).encode(),
                                family_name="b",
                                qualifier=b"c",
                                value=b"d",
                                commit_row=True,
                            )
                        ]
                    )

            return mock_stream()

        query = ReadRowsQuery(limit=start_limit)
        table = mock.Mock()
        table.table_name = "table_name"
        table.app_profile_id = "app_profile_id"
        instance = self._make_one(query, table, 10, 10)
        assert instance._remaining_count == start_limit
        for val in instance.chunk_stream(awaitable_stream()):
            pass
        assert instance._remaining_count == expected_limit

    @pytest.mark.parametrize("start_limit,emit_num", [(5, 10), (3, 9), (1, 10)])
    def test_revise_limit_over_limit(self, start_limit, emit_num):
        """
        Should raise runtime error if we get in state where emit_num > start_num
        (unless start_num == 0, which represents unlimited)
        """
        from google.cloud.bigtable.data import ReadRowsQuery
        from google.cloud.bigtable_v2.types import ReadRowsResponse
        from google.cloud.bigtable.data.exceptions import InvalidChunk

        def awaitable_stream():
            def mock_stream():
                for i in range(emit_num):
                    yield ReadRowsResponse(
                        chunks=[
                            ReadRowsResponse.CellChunk(
                                row_key=str(i).encode(),
                                family_name="b",
                                qualifier=b"c",
                                value=b"d",
                                commit_row=True,
                            )
                        ]
                    )

            return mock_stream()

        query = ReadRowsQuery(limit=start_limit)
        table = mock.Mock()
        table.table_name = "table_name"
        table.app_profile_id = "app_profile_id"
        instance = self._make_one(query, table, 10, 10)
        assert instance._remaining_count == start_limit
        with pytest.raises(InvalidChunk) as e:
            for val in instance.chunk_stream(awaitable_stream()):
                pass
        assert "emit count exceeds row limit" in str(e.value)

    def test_close(self):
        """
        should be able to close a stream safely with aclose.
        Closed generators should raise StopIteration on next yield
        """

        def mock_stream():
            while True:
                yield 1

        with mock.patch.object(
            self._get_target_class(), "_read_rows_attempt"
        ) as mock_attempt:
            instance = self._make_one(mock.Mock(), mock.Mock(), 1, 1)
            wrapped_gen = mock_stream()
            mock_attempt.return_value = wrapped_gen
            gen = instance.start_operation()
            gen.__next__()
            gen.close()
            with pytest.raises(StopIteration):
                gen.__next__()
            gen.close()
            with pytest.raises(StopIteration):
                wrapped_gen.__next__()

    def test_retryable_ignore_repeated_rows(self):
        """Duplicate rows should cause an invalid chunk error"""
        from google.cloud.bigtable.data.exceptions import InvalidChunk
        from google.cloud.bigtable_v2.types import ReadRowsResponse

        row_key = b"duplicate"

        def mock_awaitable_stream():
            def mock_stream():
                while True:
                    yield ReadRowsResponse(
                        chunks=[
                            ReadRowsResponse.CellChunk(row_key=row_key, commit_row=True)
                        ]
                    )
                    yield ReadRowsResponse(
                        chunks=[
                            ReadRowsResponse.CellChunk(row_key=row_key, commit_row=True)
                        ]
                    )

            return mock_stream()

        instance = mock.Mock()
        instance._last_yielded_row_key = None
        instance._remaining_count = None
        stream = self._get_target_class().chunk_stream(
            instance, mock_awaitable_stream()
        )
        stream.__next__()
        with pytest.raises(InvalidChunk) as exc:
            stream.__next__()
        assert "row keys should be strictly increasing" in str(exc.value)
